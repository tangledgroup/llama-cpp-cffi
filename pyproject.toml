[project]
name = "llama-cpp-cffi"
version = "0.3.3"
description = "Python binding for llama.cpp using cffi"
homepage = "https://github.com/tangledgroup/llama-cpp-cffi"
repository = "https://github.com/tangledgroup/llama-cpp-cffi"
license = "MIT"
readme = "README.md"
authors = [
    { name = "Marko Tasic", email = "mtasic85@gmail.com" },
    { name = "Tangled Group, Inc", email = "info@tangledgroup.com" }
]
requires-python = ">=3.10"
dependencies = [
    "aiohttp>=3.11.11",
    "attrs>=24.3.0",
    "gunicorn>=23.0.0",
    "huggingface-hub>=0.27.1",
    "jinja2>=3.1.5",
    "numba>=0.60.0",
    "openai>=1.59.5",
    "protobuf>=5.29.3",
    "psutil>=6.1.1",
    "sentencepiece>=0.2.0",
    "transformers>=4.47.1",
    "uvloop>=0.21.0",
    "vulkan>=1.3.275.1",
]

# [project.scripts]
# build = "scripts.build:build"
# clean = "scripts.clean:clean"

[build-system]
requires = ["hatchling", "cffi"]
build-backend = "hatchling.build"

[tool.hatch.build.targets.wheel]
packages = ["src/llama"]

artifacts = [
  "*.so",
  "*.dll",
  "*.dylib",
  "*.pyd",
]

[tool.hatch.envs.hatch-build]
dependencies = [
  "cffi>=1.17.1",
]

[tool.hatch.build.targets.wheel.hooks.clean]
path = "clean.py"
